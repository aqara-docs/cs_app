import streamlit as st
import pandas as pd
import gspread
from google.oauth2.service_account import Credentials
import numpy as np
from datetime import datetime
import re
import mysql.connector
from sqlalchemy import create_engine
import os
from dotenv import load_dotenv
load_dotenv()

# Set page configuration
st.set_page_config(page_title="ìˆ˜ê±°ì‹ ì²­ëŒ€ì¥", page_icon="ğŸ“‹", layout="wide")

# Page header
st.write("# ìˆ˜ê±°ì‹ ì²­ëŒ€ì¥ ê´€ë¦¬ ì‹œìŠ¤í…œ")

# Path to your service account JSON file
SERVICE_ACCOUNT_FILE = os.getenv('SERVICE_ACCOUNT_FILE')

# Load credentials from the JSON file
creds = Credentials.from_service_account_file(SERVICE_ACCOUNT_FILE, scopes=[os.getenv('SCOPES')])

# Connect to Google Sheets
gc = gspread.authorize(creds)

# Google Sheet ID and Worksheet name
SERVICE_SPREADSHEET_ID = os.getenv('SERVICE_SPREADSHEET_ID')
SERVICE_WORKSHEET_NAME = os.getenv('SERVICE_WORKSHEET_NAME')  # Replace with your worksheet name

# Function to make column names unique
def make_unique_columns(columns):
    seen = {}
    for idx, col in enumerate(columns):
        if col in seen:
            seen[col] += 1
            columns[idx] = f"{col}_{seen[col]}"
        else:
            seen[col] = 0
    return columns

# Function to load data from Google Sheets
def load_sheet_data():
    worksheet = gc.open_by_key(SERVICE_SPREADSHEET_ID).worksheet(SERVICE_WORKSHEET_NAME)
    
    # Get all values from the sheet
    all_values = worksheet.get_all_values()
    
    # Skip the first two rows and set the 3rd row as header
    headers = all_values[2]  # Use the 3rd row as the header
    data = all_values[3:]    # Data starts from the 4th row
    
    # Create DataFrame
    df = pd.DataFrame(data, columns=headers)
    df.replace('', np.nan, inplace=True)
    df.dropna(subset=['ê³ ê°ëª…'], inplace=True)

    # Make column names unique
    df.columns = make_unique_columns(list(df.columns))
    
    return df

# Load the data
df = load_sheet_data()

if not df.empty:
    # Verify the correct column names
    if 'ì‘ì„±ì¼' in df.columns:
        # Initialize 'registered_date' column with None
        df['registered_date'] = None
        
        # Attempt to parse dates in multiple formats using regular expressions to detect the format
        for idx, row in df.iterrows():
            date_str = row['ì‘ì„±ì¼']
            
            if pd.isna(date_str):
                continue

            try:
                if re.match(r'^\d{4}\.\d{1,2}\.\d{1,2}$', date_str):
                    # Parse format '%Y.%m.%d'
                    df.at[idx, 'registered_date'] = pd.to_datetime(date_str, format='%Y.%m.%d')
                elif re.match(r'^\d{1,2}/\d{1,2}$', date_str):
                    # Parse format '%m/%d' and add current year
                    parsed_date = pd.to_datetime(date_str, format='%m/%d')
                    parsed_date = parsed_date.replace(year=datetime.now().year)
                    df.at[idx, 'registered_date'] = parsed_date
                elif re.match(r'^\d{4}\.\s?\d{1,2}\.\d{1,2}$', date_str):
                    # Parse format '%Y. %m %d' or '%Y.%m.%d' with optional spaces
                    df.at[idx, 'registered_date'] = pd.to_datetime(date_str, format='%Y. %m.%d')
                elif re.match(r'^\d{4}\.\s?\d{1,2}\s\d{1,2}$', date_str):
                    # Parse format '%Y. %m %d' without periods after the month
                    df.at[idx, 'registered_date'] = pd.to_datetime(date_str, format='%Y. %m %d')
                else:
                    df.at[idx, 'registered_date'] = None  # If format is not matched, set as None
            except Exception as e:
                print(f"Error parsing date {date_str}: {e}")
                df.at[idx, 'registered_date'] = None

        # Remove the original 'ì‘ì„±ì¼' column
        df.drop(columns=['ì‘ì„±ì¼'], inplace=True)

        # Reorder columns to move 'registered_date' before 'ì‘ì„±ì'
        columns = df.columns.tolist()
        if 'ì‘ì„±ì' in columns:
            author_index = columns.index('ì‘ì„±ì')
            columns.insert(author_index, columns.pop(columns.index('registered_date')))
            df = df[columns]

    # Replace NaN values in the DataFrame with None for SQL compatibility
    df.replace({np.nan: None, '': None}, inplace=True)

    # Convert 'ì™„ë£Œ' and 'ì£¼ì†Œë³€ê²½' to boolean values (1 for TRUE, 0 for FALSE)
    boolean_columns = ['ì™„ë£Œ', 'ì£¼ì†Œë³€ê²½']
    for col in boolean_columns:
        if col in df.columns:
            df[col] = df[col].map({'TRUE': 1, 'FALSE': 0, None: 0})  # Convert 'TRUE'/'FALSE' to 1/0, default to 0 if None

    # Ensure all required columns are present and fill missing columns with default values
    required_columns = [
        'ì™„ë£Œ', 'registered_date', 'ì‘ì„±ì', 'êµ¬ë¶„', 'ì‚¬ìœ ', 'ë°°ì†¡ë¹„', 'ì£¼ë¬¸ì²˜', 'ì£¼ë¬¸ë²ˆí˜¸', 'ê³ ê°ëª…', 
        'ì—°ë½ì²˜', 'ì£¼ì†Œë³€ê²½', 'ìš°í¸ë²ˆí˜¸', 'ì£¼ì†Œ', 'ì œí’ˆ', 'ìˆ˜ëŸ‰', 'ë¹„ê³ ', 'ìˆ˜ê±°ì‹ ì²­',
        'ìˆ˜ê±°ì™„ë£Œ', 'êµí™˜ì¶œê³ ', 'í™˜ë¶ˆì²˜ë¦¬', 'íƒë°°ì‚¬', 
        'ì›ì†¡ì¥', 'ë°˜ì†¡ì¥', 'êµí™˜ì¶œê³ ì†¡ì¥', 'ì¡°ì¹˜'
    ]

    df = df[required_columns]

    # Convert numeric columns to appropriate types
    numeric_columns = ['ìˆ˜ëŸ‰']
    for col in numeric_columns:
        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)

    # Convert datetime columns to appropriate types for MySQL
    datetime_columns = ['registered_date']
    for col in datetime_columns:
        if col in df.columns:
            df[col] = pd.to_datetime(df[col], errors='coerce').dt.strftime('%Y-%m-%d')

    # Display the DataFrame
    st.dataframe(df)

    # MySQL ë°ì´í„°ë² ì´ìŠ¤ì— DataFrame ì‚½ì…
    try:
        # Create a connection using mysql.connector
        conn = mysql.connector.connect(
            user =  os.getenv('SQL_USER'),
            password =  os.getenv('SQL_PASSWORD'),
            host =  os.getenv('SQL_HOST'),
            database =  os.getenv('SQL_DATABASE'),   # ë¹„ë°€ë²ˆí˜¸
            charset='utf8mb4',       # UTF-8ì˜ í•˜ìœ„ ì§‘í•©ì„ ì‚¬ìš©í•˜ëŠ” ë¬¸ìì…‹ ì„¤ì •
            collation='utf8mb4_general_ci'  # ì¼ë°˜ì ì¸ Collation ì„¤ì •
        )

        cursor = conn.cursor()

        # Iterate through each row in the DataFrame
        for idx, row in df.iterrows():
            # Replace NaN with None
            row = row.where(pd.notnull(row), None)

            # Validate date values and set invalid dates to None
            for date_col in ['registered_date']:
                if row[date_col] and not re.match(r'^\d{4}-\d{2}-\d{2}$', str(row[date_col])):
                    row[date_col] = None

            # Ensure key fields are not None or empty
            if not row['registered_date'] or not row['ê³ ê°ëª…'] or not row['ì£¼ë¬¸ë²ˆí˜¸'] or not row['ì œí’ˆ']:
               # st.warning(f"Skipping row {idx} because key fields are missing.")
                continue

            # Define the SQL query to check for existing records
            check_query = """
            SELECT COUNT(*) FROM service_ledger 
            WHERE registered_date = %s AND ê³ ê°ëª… = %s AND ì£¼ë¬¸ë²ˆí˜¸ = %s AND ì œí’ˆ = %s
            """
            
            # Execute the query with parameters
            cursor.execute(check_query, (row['registered_date'], row['ê³ ê°ëª…'], row['ì£¼ë¬¸ë²ˆí˜¸'], row['ì œí’ˆ']))
            result = cursor.fetchone()

            if result[0] > 0:
                # If a matching record exists, perform an update
                #st.write(f"Updating record for {row['ê³ ê°ëª…']} with ì£¼ë¬¸ë²ˆí˜¸ {row['ì£¼ë¬¸ë²ˆí˜¸']}")
                #st.write("Existing records have been updated!!")
                update_query = """
                UPDATE service_ledger 
                SET ì™„ë£Œ = %s, ì‘ì„±ì = %s, êµ¬ë¶„ = %s, ì‚¬ìœ  = %s, ë°°ì†¡ë¹„ = %s, ì£¼ë¬¸ì²˜ = %s,
                    ì—°ë½ì²˜ = %s, ì£¼ì†Œë³€ê²½ = %s, ìš°í¸ë²ˆí˜¸ = %s, ì£¼ì†Œ = %s, ìˆ˜ëŸ‰ = %s, ë¹„ê³  = %s, ìˆ˜ê±°ì‹ ì²­ = %s, 
                    ìˆ˜ê±°ì™„ë£Œ = %s, êµí™˜ì¶œê³  = %s, í™˜ë¶ˆì²˜ë¦¬ = %s, íƒë°°ì‚¬ = %s, ì›ì†¡ì¥ = %s, 
                    ë°˜ì†¡ì¥ = %s, êµí™˜ì¶œê³ ì†¡ì¥ = %s, ì¡°ì¹˜ = %s
                WHERE registered_date = %s AND ê³ ê°ëª… = %s AND ì£¼ë¬¸ë²ˆí˜¸ = %s AND ì œí’ˆ = %s
                """
                
                # Execute the update query
                cursor.execute(update_query, (
                    row['ì™„ë£Œ'], row['ì‘ì„±ì'], row['êµ¬ë¶„'], row['ì‚¬ìœ '], row['ë°°ì†¡ë¹„'], row['ì£¼ë¬¸ì²˜'],
                    row['ì—°ë½ì²˜'], row['ì£¼ì†Œë³€ê²½'], row['ìš°í¸ë²ˆí˜¸'], row['ì£¼ì†Œ'], row['ìˆ˜ëŸ‰'], row['ë¹„ê³ '], row['ìˆ˜ê±°ì‹ ì²­'],
                    row['ìˆ˜ê±°ì™„ë£Œ'], row['êµí™˜ì¶œê³ '], row['í™˜ë¶ˆì²˜ë¦¬'], row['íƒë°°ì‚¬'], row['ì›ì†¡ì¥'],
                    row['ë°˜ì†¡ì¥'], row['êµí™˜ì¶œê³ ì†¡ì¥'], row['ì¡°ì¹˜'],
                    row['registered_date'], row['ê³ ê°ëª…'], row['ì£¼ë¬¸ë²ˆí˜¸'], row['ì œí’ˆ']
                ))
            else:
                # If no matching record exists, perform an insert
                st.write(f"Inserting new record for {row['ê³ ê°ëª…']} with ì£¼ë¬¸ë²ˆí˜¸ {row['ì£¼ë¬¸ë²ˆí˜¸']}")
                
                insert_query = """
                INSERT INTO service_ledger (ì™„ë£Œ, registered_date, ì‘ì„±ì, êµ¬ë¶„, ì‚¬ìœ , ë°°ì†¡ë¹„, ì£¼ë¬¸ì²˜, ì£¼ë¬¸ë²ˆí˜¸, ê³ ê°ëª…, 
                    ì—°ë½ì²˜, ì£¼ì†Œë³€ê²½, ìš°í¸ë²ˆí˜¸, ì£¼ì†Œ, ì œí’ˆ, ìˆ˜ëŸ‰, ë¹„ê³ , ìˆ˜ê±°ì‹ ì²­,
                    ìˆ˜ê±°ì™„ë£Œ, êµí™˜ì¶œê³ , í™˜ë¶ˆì²˜ë¦¬, íƒë°°ì‚¬, ì›ì†¡ì¥, ë°˜ì†¡ì¥, êµí™˜ì¶œê³ ì†¡ì¥, ì¡°ì¹˜) 
                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                """
                
                # Execute the insert query
                cursor.execute(insert_query, (
                    row['ì™„ë£Œ'], row['registered_date'], row['ì‘ì„±ì'], row['êµ¬ë¶„'], row['ì‚¬ìœ '], row['ë°°ì†¡ë¹„'], row['ì£¼ë¬¸ì²˜'],
                    row['ì£¼ë¬¸ë²ˆí˜¸'], row['ê³ ê°ëª…'], row['ì—°ë½ì²˜'], row['ì£¼ì†Œë³€ê²½'], row['ìš°í¸ë²ˆí˜¸'], row['ì£¼ì†Œ'], row['ì œí’ˆ'], 
                    row['ìˆ˜ëŸ‰'], row['ë¹„ê³ '], row['ìˆ˜ê±°ì‹ ì²­'], row['ìˆ˜ê±°ì™„ë£Œ'], row['êµí™˜ì¶œê³ '], row['í™˜ë¶ˆì²˜ë¦¬'], row['íƒë°°ì‚¬'], row['ì›ì†¡ì¥'], 
                    row['ë°˜ì†¡ì¥'], row['êµí™˜ì¶œê³ ì†¡ì¥'], row['ì¡°ì¹˜']
                ))

        # Commit changes to the database
        conn.commit()

        st.success("Data has been successfully inserted or updated in the MySQL database!")

    except Exception as e:
        st.error(f"An error occurred while inserting or updating data in MySQL: {e}")

    finally:
        # Close the connection
        if conn.is_connected():
            cursor.close()
            conn.close()

else:
    st.warning("No data available to process.")